"""
Library of all functions to implement SINDy. File to be used with paralelized AFM_SINDy_single_training_instance.py
"""

### Importing Required Packages
import numpy as np
import math #available on 2024r1
import pandas as pd
import dill #installed myself via conda install dill
import cvxpy #installed myslef via conda install -c conda-forge cvxpy
import pysindy as ps #installed myself via conda install pysindy

# SciPy & NumPy
from scipy.integrate import solve_ivp #already installed on conda env mac_python
from scipy.interpolate import CubicSpline #already installed on conda env mac_python

# Sklearn
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import NearestNeighbors
from sklearn.cluster import KMeans
from sklearn.linear_model import (
    LinearRegression, Lasso, ElasticNet, Ridge, 
    OrthogonalMatchingPursuit, Lars, LassoLars
)

# Matplotlib & Plotting
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
from mpl_toolkits.mplot3d import Axes3D
from IPython.display import Image

# Miscellaneous
import os
from tqdm import tqdm #installed myself via conda install tqdm
from datetime import datetime #is part of python already
import itertools

# PySINDy utilities
from pysindy.utils import lorenz, lorenz_control, enzyme

def set_plot_style(style_num = 17):
    # Version 2.0: This function sets the style of the images that are generated by matplotlib. 
    # New in Version 2.0: Added functionality to put back the plotting style to 'default' when styly_num = 'default'.
    plt.style.use('default')
    plt.style.use(plt.style.available[style_num])

    if style_num == 'default': # New in version 2.0
        plt.style.use('default')


### -------------------- 1. Data Generation Functions --------------------

def add_gaussian_noise(x_train, noise_level):
    """
    Adds Gaussian noise to the training data.

    Parameters:
        x_train (np.array): The original training data.
        noise_level (float): The desired noise level as a percentage.

    Returns:
        np.array: A new dataset with added Gaussian noise.
    """
    rmse = mean_squared_error(x_train, np.zeros(x_train.shape), squared=False)
    noise = np.random.normal(0, rmse * (noise_level / 100.0), x_train.shape)
    x_train_with_noise = x_train + noise
    return x_train_with_noise


def generate_different_trajectories(dynamical_system, num_trajectories, t_train, init_cond_range, DOF, 
                                    noise_level, method='RK45', parameters=None, noisy_trajectories=False, 
                                    add_ivp_time_array=False):
    """
    Generates multiple trajectories of synthetic data from different initial conditions.

    Parameters:
        dynamical_system (function): The system's differential equations.
        num_trajectories (int): Number of trajectories to generate.
        t_train (np.array): Time array.
        init_cond_range (list of tuples): Range for initial conditions.
        DOF (int): Degrees of freedom.
        noise_level (float): Noise level in percentage.
        method (str): Solver method (default: 'RK45').
        parameters (tuple, optional): Additional parameters for the system.
        noisy_trajectories (bool): If True, adds noise.
        add_ivp_time_array (bool): If True, includes time array.

    Returns:
        list: Trajectories and initial conditions.
    """
    t_train_span = (t_train[0], t_train[-1])
    trajectories_list = []
    init_cond_list = []
    for trajectory in tqdm(range(num_trajectories), desc="Generating Trajectories"):     # For loop with "tqdm" to add a progress bar
        init_cond_disp = np.random.uniform(init_cond_range[0][0], init_cond_range[0][1])
        init_cond_vel = np.random.uniform(init_cond_range[1][0], init_cond_range[1][1])
        init_cond_phase = np.random.uniform(init_cond_range[2][0], init_cond_range[2][1])

        if DOF == 1:
            init_cond = np.array([init_cond_disp])
        elif DOF == 2:
            init_cond = np.array([init_cond_disp, init_cond_vel])
        elif DOF == 3:
            init_cond = np.array([init_cond_disp, init_cond_vel, init_cond_phase])

        init_cond_list.append(init_cond)

        if parameters is None:
            solution_ivp = solve_ivp(dynamical_system, t_train_span, init_cond, t_eval=t_train, rtol=1e-6, atol=1e-8, method=method, dense_output=True)
        else:
            solution_ivp = solve_ivp(dynamical_system, t_train_span, init_cond, t_eval=t_train, args=parameters, rtol=1e-6, atol=1e-8, method=method, dense_output=True)
        
        x_train = solution_ivp.y.T
        t_train_ivp = solution_ivp.t

        if noisy_trajectories:
            x_train = add_gaussian_noise(x_train, noise_level) 
        
        if add_ivp_time_array:
            x_train = np.vstack((x_train[:,0], x_train[:,1], t_train)).T

        trajectories_list.append(x_train)

    return trajectories_list, init_cond_list


### -------------------- 2. Measurement Processing Functions --------------------

def get_displacement_measurements(measurement_trajectories, dt, multiple_trajectories=False):
    """
    Extracts displacement from trajectories and estimates velocity numerically.

    Parameters:
        measurement_trajectories (list or np.array): Input trajectories.
        dt (float): Time step.
        multiple_trajectories (bool): If True, handles multiple trajectories.

    Returns:
        list or np.array: Displacement and estimated velocity.
    """
    if multiple_trajectories:
        return [np.column_stack((data[:, 0], np.gradient(data[:, 0], dt))) for data in measurement_trajectories]
    return np.column_stack((measurement_trajectories[:, 0], np.gradient(measurement_trajectories[:, 0], dt)))


### -------------------- 3. Force Calculation Functions --------------------

def calculate_true_F_ts_LJ(sim_disp_data, C11, C12):
    #Version 1.0: This function takes the array of simulated data and calculates the Tip-Sample Force using the LJ potencial.

    #Parameters: - sim_disp_data: Synthetic data generated with the function AFM_w_Lennard_Jones().
    #                             It can be either a single measurement in an np.array or multiple trajectories in a list.
    #            - C11 & C12: Float numbers containing the parameters C11 and C12 of LJ potential
    if isinstance(sim_disp_data, np.ndarray):
        F_ts_true_array = np.zeros_like(sim_disp_data[:,0],dtype=float)
        for i in range(len(sim_disp_data)):
            x_elem = sim_disp_data[i, 0]
            F_ts_temp = (C11 / ((1 - x_elem) ** 8))+(C12 / ((1 - x_elem) ** 2))
            F_ts_true_array[i] = F_ts_temp
        return -1*F_ts_true_array 

    if isinstance(sim_disp_data, list):
        F_ts_true_list = []
        for trajectory in sim_disp_data:
            F_ts_true_array = np.zeros_like(trajectory[:,0], dtype=float)  # moved inside
            for i in range(len(trajectory)):
                x_elem = trajectory[i, 0]
                F_ts_temp = (C11 / ((1 - x_elem) ** 8))+(C12 / ((1 - x_elem) ** 2))
                F_ts_true_array[i] = F_ts_temp
            F_ts_true_list.append(-1 * F_ts_true_array.copy())  # optionally use .copy() to be safe

        return F_ts_true_list
#-----------------------------------   

def calculate_AFM_DMT_Force(eta_1, a0, C1, C2):
    
    if 1-eta_1 <= a0: 
        F_ts_temp = (C1/(a0**2)) + C2* (a0-(1 - eta_1))**1.5 #Repulsive regime
    else: 
        F_ts_temp = (C1/(1-eta_1)**(2))  #Attractive regime Force

    return F_ts_temp 

def calculate_true_F_ts_DMT(sim_disp_data, a0, C1, C2):
    #Version 1.0: This function takes the array of simulated data and calculates the Tip-Sample Force using the DMT model.

    #Parameters: - sim_disp_data: Synthetic data generated with the function AFM_w_DMT().
    #                             It can be either a single measurement in an np.array or multiple trajectories in a list.
    #            - C11 & C12: Float numbers containing the parameters C1 and C2 of DMT model.
    if isinstance(sim_disp_data, np.ndarray):
        F_ts_true_array = np.zeros_like(sim_disp_data[:,0],dtype=float)
        for i in range(len(sim_disp_data)):
            x_elem = sim_disp_data[i, 0]
            F_ts_temp = calculate_AFM_DMT_Force(eta_1=x_elem, a0=a0, C1=C1, C2=C2)
            F_ts_true_array[i] = F_ts_temp
        return F_ts_true_array 

    if isinstance(sim_disp_data, list):
        F_ts_true_list = []
        for trajectory in sim_disp_data:
            F_ts_true_array = np.zeros_like(trajectory[:,0], dtype=float)
            for i in range(len(trajectory)):
                x_elem = trajectory[i, 0]
                F_ts_temp = calculate_AFM_DMT_Force(eta_1=x_elem, a0=a0, C1=C1, C2=C2)
                F_ts_true_array[i] = F_ts_temp
            F_ts_true_list.append(F_ts_true_array.copy())

        return F_ts_true_list
#-----------------------------------

def calculate_AFM_DMT_viscoelas_damp_Force(eta_1, eta_2, a0, C1, C2, C3):
    
    if 1-eta_1 <= a0: 
        F_ts_temp = (C1/(a0**2)) + C2* (a0-(1 - eta_1))**1.5 - C3*(((a0-(1 - eta_1))**(0.5))*eta_2) #Repulsive regime
    else: 
        F_ts_temp = (C1/(1-eta_1)**(2))  #Attractive regime Force

    return F_ts_temp 

def calculate_true_F_ts_DMT_viscoelast_damp(sim_disp_data, a0, C1,C2,C3):
    #Version 1.0: This function takes the array of simulated data and calculates the Tip-Sample Force using the DMT model.

    #Parameters: - sim_disp_data: Synthetic data generated with the function AFM_w_Lennard_Jones().
    #                             It can be either a single measurement in an np.array or multiple trajectories in a list.
    #            - C11 & C12: Float numbers containing the parameters C11 and C12 of LJ potential
    if isinstance(sim_disp_data, np.ndarray):
        F_ts_true_array = np.zeros_like(sim_disp_data[:,0],dtype=float)
        for i in range(len(sim_disp_data)):
            x_elem = sim_disp_data[i, 0]
            y_elem = sim_disp_data[i, 1]
            F_ts_temp = calculate_AFM_DMT_viscoelas_damp_Force(eta_1=x_elem, eta_2=y_elem, a0=a0, C1=C1, C2=C2, C3=C3)
            F_ts_true_array[i] = F_ts_temp
        return F_ts_true_array 
    
    if isinstance(sim_disp_data, list):
        F_ts_true_list = []
        for trajectory in sim_disp_data:
            F_ts_true_array = np.zeros_like(trajectory[:,0], dtype=float)
            for i in range(len(trajectory)):
                x_elem = trajectory[i, 0]
                y_elem = trajectory[i, 1]  # This line was missing
                F_ts_temp = calculate_AFM_DMT_viscoelas_damp_Force(
                    eta_1=x_elem, eta_2=y_elem, a0=a0, C1=C1, C2=C2, C3=C3)
                F_ts_true_array[i] = F_ts_temp
            F_ts_true_list.append(F_ts_true_array.copy())  # .copy() to avoid overwriting
        return F_ts_true_list


### -------------------- 4. AFM Data Functions --------------------

def get_true_AFM_displacement(afm_disp_array, eta_star, tau_array, omega_0):
    true_displacement = afm_disp_array*eta_star
    true_time = tau_array/omega_0

    return true_displacement, true_time

def get_true_AFM_velocity(afm_vel_array, eta_star, tau_array, omega_0):
    true_velocity = afm_vel_array*(eta_star*omega_0)
    true_time = tau_array/omega_0

    return true_velocity, true_time


### -------------------- 5. Candidate Function Generation --------------------

def make_sine(f):
    return lambda x: np.sin(f*x)

def make_sine_name(f):
    return lambda x: f"sin({f}*{x})"
#-----------------------------------

def make_cosine(f):
    return lambda x: np.cos(f*x)

def make_cosine_name(f):
    return lambda x: f"cos({f}*{x})"
#-----------------------------------

def make_poly(degree):
    if degree == 1:
        return lambda x: x
    else:
        return lambda x: x**degree

def make_poly_name(degree):
    if degree == 1:
        return lambda x: x
    else:
        return lambda x: x+'^'+str(degree)
#-----------------------------------

def make_poly_comb(DOF):
    if DOF == 2:
        return lambda x,y: x*y
    if DOF == 3:
        return lambda x,y,z: x*y*z

def make_poly_comb_name(DOF):
    if DOF == 2:
        return lambda x,y: x+y
    if DOF == 3:
        return lambda x,y,z: x+y+z
#-----------------------------------

def make_poly_frac(degree):
    return lambda x: x**(-degree)

def make_poly_frac_name(degree):
    return lambda x: x+'^'+str(-degree)
#-----------------------------------

def make_denom_cosine(f, degree):
    return lambda x: (np.cos(f*x))**(-degree)

def make_denom_cosine_name(f, degree):
    return lambda x: f"cos({f}*{x})"+'^'+str(-degree)
#-----------------------------------

def make_denom_sine(f, degree):
    return lambda x: (np.sin(f*x))**(-degree)

def make_denom_sine_name(f, degree):
    return lambda x: f"sin({f}*{x})"+'^'+str(-degree)
#-----------------------------------

def make_special_func(degree): # This special function is to generate the Lennard Jones term (1-x)^-(degree)
    return lambda x: (1-x)**(-degree)

def make_special_func_name(degree):
    return lambda x:f"({1}-{x})"+'^'+str(-degree) 
#-----------------------------------

def make_AFM_LJ_z_func(amp, f, degree): #This function is to generate the Lennard Jones term (1-x-amp*sin(omega*t)^-(degree))
        return lambda x,y: ((1-x-(amp*(np.sin(f*y))))**(-degree))

def make_AFM_LJ_z_name(amp, f, degree):
    return lambda x,y:  f"({1}-{x}-{amp}*sin({f}*{y}))"+'^'+str(-degree) #-x+f"-sin({f}*{x})]"+'^'+str(-degree)
#-----------------------------------

### --- Functions for AFM 'z' functions ----

def make_AFM_z_smooth_func(degree):   #This function is to generate the AFM term z^degree =  (1-x)^(degree)
    return lambda x: (1-x)**(degree)

def make_AFM_z_smooth_name(degree):
    return lambda x: f"({1}-{x})"+'^'+str(degree)
#-----------------------------------

def make_AFM_z_damp_smooth_func(degree, degree_2):
    #This function is to generate the DMT term ((a0-(1-x))^(0.5))*y in 
    # DMT with viscoelastic damping without considering vector field changes.
    return lambda x,y: ((1 - x)**(degree))*(y**degree_2) 

def make_AFM_z_damp_smooth_name(degree, degree_2):
    if degree == 1 and degree_2 == 1:
        return lambda x,y: f"(({1}-{x})"+f")*{y}"
    elif degree == 1:
        return lambda x,y: f"(({1}-{x})"+f")*{y}"+'^'+str(degree_2) 
    elif degree_2 == 1:
        return lambda x,y: f"(({1}-{x})"+'^'+str(degree)+f")*{y}"
    else:
        return lambda x,y: f"(({1}-{x})"+'^'+str(degree)+f")*{y}"+'^'+str(degree_2)
#-----------------------------------
    
### --- Functions for Exponential Damping ----

def make_exp_damping_func(z_b, degree):
    return lambda x,y: (y**degree)*(np.exp((1-x)/(z_b)))

def make_exp_damping_name(z_b, degree):
    if degree == 1:
        return lambda x,y: f"{y}"+"*exp"+f"({1}-{x}/{z_b})"
    else:
        return lambda x,y: f"{y}"+'^'+str(degree)+"*exp"+f"({1}-{x}/{z_b})"
    
### --- Functions for DMT 'smooth' models ----

def make_AFM_DMT_rep_smooth_func(a0, degree):
    return lambda x: (a0 - 1 + x)**(degree)      

def make_AFM_DMT_rep_smooth_name(a0, degree):
    return lambda x:  f"({a0}-{1}+{x})" +'^'+str(degree)
#-----------------------------------

def make_AFM_DMT_att_smooth_func(a0, degree):
    return lambda x: (1-x)**(-degree)

def make_AFM_DMT_att_smooth_name(a0, degree):
    return lambda x: f"({1}-{x})"+'^'+str(-degree)
#-----------------------------------

### --- Functions for DMT viscoelastic'smooth' models ----

def make_AFM_DMT_viscoel_damp_smooth_func(a0):
    return lambda x,y: ((a0 - 1 + x)**(0.5))*y 

def make_AFM_DMT_viscoel_damp_smooth_name(a0):
    return lambda x,y: f"(({a0}-1+{x})^0.5)*{y}"

### --- Functions for DMT 'non-smooth' models ----

def dmt_rep(x,a0,degree):

    cand_func_array=np.zeros_like(x,dtype=float)
    for ii in range(len(x)):
        if 1 - x[ii]  < a0:
            cand_func_array[ii]=np.power(a0 - 1 + x[ii], degree)      
        else:
            cand_func_array[ii]= 0
    return cand_func_array  

def make_AFM_DMT_rep_func(x, a0, degree): #This function is to generate the DMT term (a0-(1-x))^-(degree)
    return lambda x: dmt_rep(x,a0,degree)

def make_AFM_DMT_rep_name(a0, degree):
    return lambda x:  f"({a0}-{1}+{x})" +'^'+str(degree)
#-----------------------------------

def vdw(x,a0,degree):

    cand_func_array=np.zeros_like(x,dtype=float)
    for ii in range(len(x)):
        if 1 - x[ii]  < a0:
            cand_func_array[ii]=0
        else:
            cand_func_array[ii]=(1-x[ii])**(-degree)
    return cand_func_array

def make_AFM_DMT_att_func(x, a0, degree):  #This function is to generate the DMT term (a0-(1-x))^-(degree)
    return lambda x: vdw(x,a0,degree)

def make_AFM_DMT_att_name(a0, degree):
    return lambda x: f"({1}-{x})"+'^'+str(-degree)
#-----------------------------------

def DMT_rep_viscoel_damp(x, y, a0, degree, degree_2):
#   Version 2: This function generates the discontinous function for the viscoelastic term in a DMT model 
#              of the shape ((a0-1-e1)^degree)*(e2^degree_2).
#   New in Version 2: added the funcitonality for 'y' to have a different exponent than 1 by introducing
#                     the parameter degree_2
#   Parameters : a_0 is the intermolecular distance value
#                degree is the exponent that goes with 'x' variable.
#                degree_2 is the exponent that goes with 'y' variable.

    cand_func_array=np.zeros_like(x,dtype=float)
    for ii in range(len(x)):
        if 1 - x[ii]  < a0:
            cand_func_array[ii]=((a0 - 1 + x[ii])**(degree))*(y[ii]**degree_2) #here before it was hardcoded so that degree was always 0.5
        else:
            cand_func_array[ii]= 0
    return cand_func_array  

def make_AFM_DMT_viscoel_damp_func(x, y, a0, degree, degree_2):                     
    return lambda x,y: DMT_rep_viscoel_damp(x, y, a0, degree, degree_2)

def make_AFM_DMT_viscoel_damp_name(a0, degree, degree_2):
    if degree == 1 and degree_2 == 1:
        return lambda x,y: f"(({a0}-1+{x})"+f")*{y}"
    elif degree == 1:
        return lambda x,y: f"(({a0}-1+{x})"+f")*{y}"+'^'+str(degree_2) 
    elif degree_2 == 1:
        return lambda x,y: f"(({a0}-1+{x})"+'^'+str(degree)+f")*{y}"
    else:
        return lambda x,y: f"(({a0}-1+{x})"+'^'+str(degree)+f")*{y}"+'^'+str(degree_2) 
    

### -------------------- 6. Candidate Function Library Generation --------------------
    
def to_ranges(value):
#     Version 2.0: To be used in the function create_candidate_func_w_func_names(). 
#     It Converts an input value to a set of integers (handles both single integers and tuples/ranges)
#     The idea is to be able to generate only the powers of a candidate function that are needed. In a polynomial library for instance
#     To generate only powers of 2, 5,6,7 10 can be written as poly_degrees=[2, (5,7), 10].
#     New in version 2.0: Modified to handle floats in addition to integers and ranges.

    result = set()
    if isinstance(value, (int, float)):
        result.add(value)  # If it's an integer or float, add it to the set
    elif isinstance(value, (tuple, list)) and len(value) == 2:
        start, end = value
        if all(isinstance(v, (int, float)) for v in (start, end)):
            # If both elements are int or float, generate the range.
            # Using a step of 1 for int range, approximate steps for float range.
            if isinstance(start, int) and isinstance(end, int):
                result.update(range(start, end + 1))
            else:
                # Generate numbers from start to end, with an increment that approximates integer steps.
                increment = 1 if start < end else -1
                while start <= end:
                    result.add(start)
                    start += increment
        else:
            raise ValueError(f"Both elements in the tuple/list must be integers or floats. Received: {value}")
    else:
        raise ValueError(f"Invalid input, expected int, float, or tuple/list with two integers or floats. Received: {value}")
    return result

def create_candidate_func_w_func_names(DOF, poly_degrees=None, special_degrees=None, DMT_rep_degrees=None, DMT_att_degrees=None, n_frequencies=None, AFM_amp=None, a0_val = None, DMT_data = None,
                                       poly=True, poly_frac=False, sin=False, cos=False, exp_damp = False, z_b_val=None, exp_damp_degrees = None,
                                       sin_denominator=False, cos_denominator=False, AFM_z=False, AFM_z_degrees = None, special=False, AFM_LJ_z=False,
                                       AFM_z_damp=False, AFM_z_damp_degrees_e1 = None, AFM_z_damp_degrees_e2 = None,
                                       DMT_rep = False, DMT_att = False, DMT_rep_smooth=False, DMT_smooth_viscoel_damp = False, 
                                       DMT_viscoel_damp=False, DMT_visc_elast_degrees_e1=None, DMT_visc_elast_degrees_e2=None):
    
    #Version 2.0: This function uses candidate functions created with lambda functions to generate a library of candidate functions for SINDy.

    #Parameters: DOF: Number of generalized coordinates in the system. (DOF=3 if we have x,y,phase)
    #            poly: Boolean to determine if normal polynomial terms should be included in the library. 
    #            poly_degrees: A list that states the degrees that the library should create for normal polynomial functions. Example: poly_degrees = [2, (4,6), 8] (generates 2nd, 4th,5th, 6th and 8th degree polynomials)
    #            special: Boolean to determine if a special AFM function should be created. Special AFM are of the form "(1-x)^(-degree)"
    #            special_degrees: A list that states the degrees that the library should create for special AFM polynomial functions. Example: special_degrees = [2, (4,6), 8] (generates 2nd, 4th,5th, 6th and 8th degree special polynomials)
    #            sin: Boolean to determine if a np.sin() should be created 
    #            cos: Boolean to determine if a np.cos() should be created
    #            sin_denominator: Boolean to determine if a "np.sin()^(-degree)"" should be created 
    #            cos_denominator: Boolean to determine if a "np.cos()^(-degree)"" should be created 
    #            n_frequencies: A list that states the frequencies that the library should create for sine, cosine functions. Example: n_frequencies = [2, (4,6), 8] (sin(2*x), sin(4*x), sin(5*x), sin(6*x), sin(8*x))
    #            AFM_amp: Is the y_bar value of an AFM equation. It is an integer value (a number).
    #            poly_frac: Boolean to determine if a rational polynomial "x^(-degree)" should be created.
    #            AFM_z: Boolean to fetermine if a AFM term with the shape of "1-x-y_bar*np.sin(t)" is created. 


    library_functions = []
    library_function_names = []

    if poly:
        degrees_to_generate = set()
        for degree_spec in poly_degrees:
            degrees_to_generate.update(to_ranges(degree_spec))

        for degree in sorted(degrees_to_generate):
            poly_func = make_poly(degree)
            poly_name = make_poly_name(degree)
            library_functions.append(poly_func)
            library_function_names.append(poly_name)

    if poly_frac:
        for degree in sorted(degrees_to_generate):
            poly_frac_func = make_poly_frac(degree)
            poly_frac_name = make_poly_frac_name(degree)
            library_functions.append(poly_frac_func)
            library_function_names.append(poly_frac_name)

    frequencies_to_generate = set()
    for frequency_spec in n_frequencies:
        frequencies_to_generate.update(to_ranges(frequency_spec))

    if sin:
        for frequency in sorted(frequencies_to_generate):
            func = make_sine(frequency)
            func_name = make_sine_name(frequency)
            library_functions.append(func)
            library_function_names.append(func_name)
            
            if sin_denominator:
                for degree in sorted(degrees_to_generate):
                    func_denom = make_denom_sine(frequency, degree)
                    func_name_denom = make_denom_sine_name(frequency, degree)
                    library_functions.append(func_denom)
                    library_function_names.append(func_name_denom)

    if cos:
        for frequency in sorted(frequencies_to_generate):
            func = make_cosine(frequency)
            func_name = make_cosine_name(frequency)
            library_functions.append(func)
            library_function_names.append(func_name)
            
            if cos_denominator:
                for degree in sorted(degrees_to_generate):
                    func_denom = make_denom_cosine(frequency, degree)
                    func_name_denom = make_denom_cosine_name(frequency, degree)
                    library_functions.append(func_denom)
                    library_function_names.append(func_name_denom)

    if special:
        degrees_to_generate = set()
        for degree_spec in special_degrees:
            degrees_to_generate.update(to_ranges(degree_spec))

        for degree in sorted(degrees_to_generate):
            func = make_special_func(degree)
            func_name = make_special_func_name(degree)
            library_functions.append(func)
            library_function_names.append(func_name)

    if AFM_LJ_z:
        for frequency in sorted(frequencies_to_generate):
            for degree in sorted(degrees_to_generate):
                func = make_AFM_LJ_z_func(AFM_amp, frequency, degree)
                func_name = make_AFM_LJ_z_name(AFM_amp, frequency, degree)
                library_functions.append(func)
                library_function_names.append(func_name)

    if AFM_z:
        degrees_to_generate = set()
        for degree_spec in AFM_z_degrees:
            degrees_to_generate.update(to_ranges(degree_spec))

        for degree in sorted(degrees_to_generate):
            func = make_AFM_z_smooth_func(degree=degree)
            func_name = make_AFM_z_smooth_name(degree=degree)
            library_functions.append(func)
            library_function_names.append(func_name)

    if AFM_z_damp:
        degrees_to_generate = set()
        for degree_spec in AFM_z_damp_degrees_e1:
            degrees_to_generate.update(to_ranges(degree_spec))
            
        degrees_to_generate_for_y = set()
        for degree_spec_for_y in AFM_z_damp_degrees_e2:
            degrees_to_generate_for_y.update(to_ranges(degree_spec_for_y))

        for degree in sorted(degrees_to_generate):
            for degree_2 in sorted(degrees_to_generate_for_y):
                DMT_visco_damp = make_AFM_z_damp_smooth_func(degree=degree, degree_2=degree_2)
                DMT_visco_damp_name = make_AFM_z_damp_smooth_name(degree=degree, degree_2=degree_2)
                library_functions.append(DMT_visco_damp)
                library_function_names.append(DMT_visco_damp_name)
    
    if DMT_att:
        degrees_to_generate = set()
        for degree_spec in DMT_att_degrees:
            degrees_to_generate.update(to_ranges(degree_spec))

        for degree in sorted(degrees_to_generate):
            func = make_AFM_DMT_att_func(x=DMT_data, a0=a0_val, degree=degree)
            func_name = make_AFM_DMT_att_name(a0=a0_val, degree=degree)
            library_functions.append(func)
            library_function_names.append(func_name)

    if DMT_rep:
        degrees_to_generate = set()
        for degree_spec in DMT_rep_degrees:
            degrees_to_generate.update(to_ranges(degree_spec))

        for degree in sorted(degrees_to_generate):
            func = make_AFM_DMT_rep_func(x=DMT_data, a0=a0_val, degree=degree)
            func_name = make_AFM_DMT_rep_name(a0=a0_val, degree=degree)
            library_functions.append(func)
            library_function_names.append(func_name)

    if DMT_rep_smooth:
        degrees_to_generate = set()
        for degree_spec in DMT_rep_degrees:
            degrees_to_generate.update(to_ranges(degree_spec))

        for degree in sorted(degrees_to_generate):
            func = make_AFM_DMT_rep_smooth_func(a0=a0_val, degree=degree)
            func_name = make_AFM_DMT_rep_smooth_name(a0=a0_val, degree=degree)
            library_functions.append(func)
            library_function_names.append(func_name)

    if DMT_viscoel_damp:
        degrees_to_generate = set()
        for degree_spec in DMT_visc_elast_degrees_e1:
            degrees_to_generate.update(to_ranges(degree_spec))
            
        degrees_to_generate_for_y = set()
        for degree_spec_for_y in DMT_visc_elast_degrees_e2:
            degrees_to_generate_for_y.update(to_ranges(degree_spec_for_y))

        for degree in sorted(degrees_to_generate):
            for degree_2 in sorted(degrees_to_generate_for_y):
                DMT_visco_damp = make_AFM_DMT_viscoel_damp_func(x=DMT_data, y=DMT_data, a0=a0_val, degree=degree, degree_2=degree_2)
                DMT_visco_damp_name = make_AFM_DMT_viscoel_damp_name(a0=a0_val, degree=degree, degree_2=degree_2)
                library_functions.append(DMT_visco_damp)
                library_function_names.append(DMT_visco_damp_name)

    
    if DMT_smooth_viscoel_damp:
        DMT_visco_damp_smooth = make_AFM_DMT_viscoel_damp_smooth_func(a0=a0_val)
        DMT_visco_damp_smooth_name = make_AFM_DMT_viscoel_damp_smooth_name(a0=a0_val)
        library_functions.append(DMT_visco_damp_smooth)
        library_function_names.append(DMT_visco_damp_smooth_name)      

    if exp_damp:
        degrees_to_generate = set()
        for degree_spec in exp_damp_degrees:
            degrees_to_generate.update(to_ranges(degree_spec))

        for degree in sorted(degrees_to_generate):
            func = make_exp_damping_func(z_b=z_b_val, degree=degree)
            func_name = make_exp_damping_name(z_b=z_b_val, degree=degree)
            library_functions.append(func)
            library_function_names.append(func_name)

    return library_functions, library_function_names

def get_index_of_cand_function(SINDy_model, cand_function_to_check):
    index = None
    for idx, cand_func in enumerate(SINDy_model.get_feature_names()):
        if cand_func == cand_function_to_check:
            index= idx

    return index

### -------------------- 7. Cluster Generation Functions --------------------

def define_cluster_centers(x_train_mult_trajectories, num_points_high_res, sub_sample_val, filter_vel_max_val, index_to_plot, centers_loc, multiple_init_cond = False, plot_file_name = None, plot=False, save_plot=False):

    # Version 1.0: This function takes an array of arrays with multiple initial conditions and places points along the phase space that later would be used as
    # cluster centers
    #
    # Parameters: x_train_mult_trajectories: List of arrays, where each array contain the time signal of an initial condition with shape [num_of_data_points, 3] 
    #             num_points_high_res: Integer defining the number of high-resolution points to be used when interpolating the trajectory in the phase space.
    #             sub_sample_val: Integer defining the step size for subsampling the high-resolution points to reduce the total number of cluster centers.
    #             filter_vel_max_val: Float defining the maximum velocity threshold, below which points are considered valid for being cluster centers.
    #             index_to_plot: Integer index specifying which trajectory from the list should be plotted (used when `plot` is True).
    #             centers_loc: Integer determining the location of centers; typically 2 for synthetic data and 5 or 6 for experimental data, affecting how the starting and ending points of closed orbits are calculated.
    #             multiple_init_cond: Boolean indicating if centers are being defined for multiple initial conditions at the same time. Default is False.
    #             plot_file_name: String specifying the filename for the plot, if saved. Relevant when `save_plot` is True.
    #             plot: Boolean to control whether to plot the phase space with the defined centers. Default is False.
    #             save_plot: Boolean to control whether to save the plot to a file. Default is False.

    cluster_centers_x = []
    cluster_centers_y = []

    if multiple_init_cond:
        for analyzed_trajectory in x_train_mult_trajectories:
            init_closed_orbit = (analyzed_trajectory.shape[0]//centers_loc) - 1000  #centers_loc is usually 2 for synthetic data
            end_closed_orbit = (analyzed_trajectory.shape[0]//centers_loc) + 1000   #centers_loc is usually 5 or 6 for experimental data

            #To extract the last closed orbit
            x = analyzed_trajectory[init_closed_orbit:end_closed_orbit,0] #[-650:,0]
            v = analyzed_trajectory[init_closed_orbit:end_closed_orbit,1]

            #Calculate the arc length for parameterization
            arc_lengths = np.zeros_like(x)
            arc_lengths[1:] = np.cumsum(np.sqrt(np.diff(x)**2 + np.diff(v)**2))

            #Parameterize the orbit by arc length
            spline_x = CubicSpline(arc_lengths, x)
            spline_v = CubicSpline(arc_lengths, v)

            # Initial high-resolution sampling
            high_res_lengths = np.linspace(arc_lengths[0], arc_lengths[-1], num_points_high_res)
            high_res_x = spline_x(high_res_lengths)
            high_res_v = spline_v(high_res_lengths)

            # Subsample every nth point, n determines the new spacing
            n = sub_sample_val 
            subsampled_x = high_res_x[::n]
            subsampled_v = high_res_v[::n]

            # Filter to keep only points with negative velocity
            negative_velocity_mask = subsampled_v < filter_vel_max_val
            filtered_x = subsampled_x[negative_velocity_mask]
            filtered_v = subsampled_v[negative_velocity_mask]
            
            cluster_centers_x.append(filtered_x)
            cluster_centers_y.append(filtered_v)

        if plot:
            fig, axs = plt.subplots(1, 1, figsize=(10, 8)) #[-650:,0]
            axs.plot(x_train_mult_trajectories[index_to_plot][:,0], x_train_mult_trajectories[index_to_plot][:,1], color='black', label='Last closed orbit', alpha = 0.7)
            axs.scatter(cluster_centers_x[index_to_plot], cluster_centers_y[index_to_plot], color='blue', label='Cluster Centers')
            axs.set_title('Phase Space Plot with Cluster Center \n Points Having Negative Velocity', fontsize=20)
            axs.set_xlabel(r'Displacement $\bar{\eta}_1$ [-]', fontsize=20)
            axs.set_ylabel(r' Velocity $\bar{\eta}_2$ [-]', fontsize=20)
            axs.legend(loc = 'upper left')
            axs.tick_params(axis='both', which='major', labelsize=20)  # Customize the font size of the tick labels
            axs.tick_params(axis='both', which='major', labelsize=20)  # Customize the font size of the tick label

            if save_plot:
                fig.savefig(f'{plot_file_name}.png', transparent=True, dpi=300, bbox_inches='tight')
            plt.show()
    
    else:
        analyzed_trajectory = x_train_mult_trajectories
        init_closed_orbit = (analyzed_trajectory.shape[0]//centers_loc) - 1000  #centers_loc is usually 2 for synthetic data
        end_closed_orbit = (analyzed_trajectory.shape[0]//centers_loc) + 1000   #centers_loc is usually 5 or 6 for experimental data

        x = analyzed_trajectory[init_closed_orbit:end_closed_orbit,0]
        v = analyzed_trajectory[init_closed_orbit:end_closed_orbit,1]  #[50000:53000]

        #Calculate the arc length for parameterization
        arc_lengths = np.zeros_like(x)
        arc_lengths[1:] = np.cumsum(np.sqrt(np.diff(x)**2 + np.diff(v)**2))

        #Parameterize the orbit by arc length
        spline_x = CubicSpline(arc_lengths, x)
        spline_v = CubicSpline(arc_lengths, v)

        # Initial high-resolution sampling
        high_res_lengths = np.linspace(arc_lengths[0], arc_lengths[-1], num_points_high_res)
        high_res_x = spline_x(high_res_lengths)
        high_res_v = spline_v(high_res_lengths)

        # Subsample every nth point, n determines the new spacing
        n = sub_sample_val 
        subsampled_x = high_res_x[::n]
        subsampled_v = high_res_v[::n]

        # Filter to keep only points with negative velocity
        negative_velocity_mask = subsampled_v < filter_vel_max_val
        filtered_x = subsampled_x[negative_velocity_mask]
        filtered_v = subsampled_v[negative_velocity_mask]
        
        cluster_centers_x.append(filtered_x)
        cluster_centers_y.append(filtered_v)

        if plot:
            fig, axs = plt.subplots(1, 1, figsize=(10, 8))
            axs.plot(x_train_mult_trajectories[:,0], x_train_mult_trajectories[:,1], color='black', label='HOPG Expeimental Data', linewidth=0.5, alpha=0.7)
            axs.scatter(cluster_centers_x[0], cluster_centers_y[0], color='blue', label='Cluster Centers')
            axs.set_title('Phase Space Plot with Cluster Center \n Points Having Negative Velocity', fontsize=20)
            axs.set_xlabel(r'Displacement $\bar{\eta}_1$ [-]', fontsize=20)
            axs.set_ylabel(r' Velocity $\bar{\eta}_2$ [-]', fontsize=20)
            axs.legend(loc = 'upper left')
            axs.tick_params(axis='both', which='major', labelsize=20)  # Customize the font size of the tick labels
            axs.tick_params(axis='both', which='major', labelsize=20)  # Customize the font size of the tick label

            if save_plot:
                fig.savefig(f'{plot_file_name}.png', transparent=True, dpi=300, bbox_inches='tight')
            plt.show()

    return cluster_centers_x, cluster_centers_y

def generate_fixed_clusters_from_centers(cluster_size, x_train_mult_trajectories, KNN_neighbors_num, mult_traj_cluster_centers_x, mult_traj_cluster_centers_y, KNN_radius = 1.0, multiple_init_cond=False):

    # Version 1.0: This function works by fitting a nearest neighbors classifier to the trajectory points and using it to find the closest neighbors around predefined
    #              cluster centers specified by the mult_traj_cluster_centers_x and mult_traj_cluster_centers_y parameters. Clusters are defined by including a fixed 
    #              number of points around each center, dictated by the cluster_size parameter. If multiple_init_cond is set to True, the function processes multiple trajectories independently.
    # 
    # Parameters:  cluster_size: Integer specifying the number of data points to include in each cluster around the cluster center.
    #              x_train_mult_trajectories: List of arrays, where each array is a trajectory with shape [num_of_data_points, dimensions] typically dimensions being 3 for 3D data.
    #              KNN_neighbors_num: Integer specifying the number of nearest neighbors to consider for determining the cluster membership.
    #              mult_traj_cluster_centers_x: List of lists containing the x-coordinates of cluster centers for multiple trajectories.
    #              mult_traj_cluster_centers_y: List of lists containing the y-coordinates of cluster centers for multiple trajectories.
    #              KNN_radius: Float specifying the radius within which to search for nearest neighbors. Default is 1.0.
    #              multiple_init_cond: Boolean indicating if the function should handle multiple trajectories simultaneously. Default is False.

    #Returns:
    #    mult_traj_clusters_sections: List of lists, where each sublist contains arrays of sections of trajectories that are part of a cluster.
    #    mult_traj_clusters_dots_list: List of lists, where each sublist contains the indices of the points in the trajectory that form a cluster around a center.

    mult_traj_clusters_dots_list = []
    mult_traj_clusters_sections = []

    if multiple_init_cond:
        for i, analyzed_trajectory in enumerate(x_train_mult_trajectories):
            KNN_traj_for_fit_temp = np.vstack((analyzed_trajectory[:,0], analyzed_trajectory[:,1])).T
            neigh = NearestNeighbors(n_neighbors=KNN_neighbors_num, radius = KNN_radius)
            neigh.fit(KNN_traj_for_fit_temp)

            single_traj_cluster_dots_list = []
            for index_center in range(len(mult_traj_cluster_centers_x[i])):
                cluster_dots_temp = neigh.kneighbors([[mult_traj_cluster_centers_x[i][index_center], mult_traj_cluster_centers_y[i][index_center]]], return_distance=False)
                single_traj_cluster_dots_list.append(cluster_dots_temp[0]) #this is always index [0] because neigh.kneighbors() gives a (1,100) array by default. So this gives (100,) already
            mult_traj_clusters_dots_list.append(single_traj_cluster_dots_list)
            
        for j, single_traj_clusters_dots in enumerate(mult_traj_clusters_dots_list):
            analyzed_trajectory = x_train_mult_trajectories[j]

            single_traj_clusters_sections = []
            for single_cluster_dots in single_traj_clusters_dots:
                single_traj_single_cluster_sections = []
                for single_cluster_dot in single_cluster_dots:
                    single_trajectory_section = np.vstack((analyzed_trajectory[(single_cluster_dot-cluster_size):(single_cluster_dot+cluster_size),0], analyzed_trajectory[(single_cluster_dot-cluster_size):(single_cluster_dot+cluster_size),1], analyzed_trajectory[(single_cluster_dot-cluster_size):(single_cluster_dot+cluster_size),2])).T
                    single_traj_single_cluster_sections.append(single_trajectory_section)
                single_traj_clusters_sections.append(single_traj_single_cluster_sections)
            mult_traj_clusters_sections.append(single_traj_clusters_sections) 

    else:
        analyzed_trajectory = x_train_mult_trajectories
        KNN_traj_for_fit_temp = np.vstack((analyzed_trajectory[:,0], analyzed_trajectory[:,1])).T
        neigh = NearestNeighbors(n_neighbors=KNN_neighbors_num, radius=KNN_radius)
        neigh.fit(KNN_traj_for_fit_temp)

        single_traj_cluster_dots_list = []
        for index_center in range(len(mult_traj_cluster_centers_x)):
            cluster_dots_temp = neigh.kneighbors([[mult_traj_cluster_centers_x[index_center], mult_traj_cluster_centers_y[index_center]]], return_distance=False)
            single_traj_cluster_dots_list.append(cluster_dots_temp[0]) #this is always index [0] because neigh.kneighbors() gives a (1,100) array by default. So this gives (100,) already
        mult_traj_clusters_dots_list.append(single_traj_cluster_dots_list)

        single_traj_clusters_dots = mult_traj_clusters_dots_list[0]
        single_traj_clusters_sections = []
        for single_cluster_dots in single_traj_clusters_dots:
            single_traj_single_cluster_sections = []
            for single_cluster_dot in single_cluster_dots:
                single_trajectory_section = np.vstack((analyzed_trajectory[(single_cluster_dot-cluster_size):(single_cluster_dot+cluster_size),0], analyzed_trajectory[(single_cluster_dot-cluster_size):(single_cluster_dot+cluster_size),1], analyzed_trajectory[(single_cluster_dot-cluster_size):(single_cluster_dot+cluster_size),2])).T
                single_traj_single_cluster_sections.append(single_trajectory_section)
            single_traj_clusters_sections.append(single_traj_single_cluster_sections)
        mult_traj_clusters_sections.append(single_traj_clusters_sections) 

    return mult_traj_clusters_sections, mult_traj_clusters_dots_list

def filter_close_points(x_points, y_points, threshold=0.2):
    filtered_x = []
    filtered_y = []

    for x, y in zip(x_points, y_points):
        # Calculate distances from the current point to all points in the filtered lists
        if filtered_x:  # Proceed only if there are already points in the filtered list
            distances = np.sqrt((np.array(filtered_x) - x) ** 2 + (np.array(filtered_y) - y) ** 2)
            # Check if all distances are above the threshold
            if np.all(distances > threshold):
                filtered_x.append(x)
                filtered_y.append(y)
        else:
            # Initialize the filtered list with the first point
            filtered_x.append(x)
            filtered_y.append(y)

    return np.array(filtered_x), np.array(filtered_y)

### -------------------- 8. SINDy Training Functions --------------------

def generate_serial_number(index, cluster, lambda_value, nu_value):
    date_str = datetime.now().strftime("%d-%m-%y")  # Current date in dd-mm-yy format
    unique_number = f"{index:03d}"  # Zero-padded 3-digit number
    return f"{date_str}-{unique_number}-{cluster}_cluster_{cluster}_lambda_{lambda_value}_nu_{nu_value}_"


def fit_constrained_SINDy_model(candidate_func_library, model_feature_names, constraint_rhs_array, constraint_lhs_array, trajectories_data, lambda_val, traject_dt, nu_val, cluster_num, script_dir, save_folder_name=None, model_filename=None, ensemble=False, multiple_trajectories=False, save_model=False):
    
    model_optimizer = ps.ConstrainedSR3(constraint_rhs=constraint_rhs_array, constraint_lhs=constraint_lhs_array, threshold=lambda_val, nu=nu_val, tol=1e-9, thresholder="l0", max_iter=10000)
    constrained_model = ps.SINDy(optimizer=model_optimizer, feature_library=candidate_func_library, feature_names=model_feature_names)
    constrained_model.fit(trajectories_data, t=traject_dt, ensemble=ensemble, multiple_trajectories=multiple_trajectories, quiet=True)

    if save_model and model_filename:
        # Ensure save_folder_name is defined
        if save_folder_name is None:
            save_folder_name = "trained_models_folder"
        
        # Define the full absolute path using script_dir
        folder_name = os.path.join(script_dir, save_folder_name)
        
        # print(f"Ensuring folder exists: {folder_name}")
        os.makedirs(folder_name, exist_ok=True)  # Create folder if it doesn't exist

        # Define the full file path
        full_path = os.path.join(folder_name, model_filename + '.dill')
        
        print(f"Saving model to: {full_path}")

        try:
            with open(full_path, 'wb') as f:
                dill.dump(constrained_model, f)
            print(f"Model saved successfully at {full_path}")
        except Exception as e:
            print(f"Error saving model: {e}")

    return constrained_model

def generate_random_lambda_n_nu(num_values, smaller_order_magnitude, bigger_order_magnitude, randomize=False):
    # Version 1: This function generates an array of lambda coeffieints to be used as threshold values for a 
    #            SINDy algorithm. I genereates lambda values from a small order to a big order of magnitude
    #            by creating logaritmically spaces values. 
    #            Note: In MATLAB, Brunton used Lambda = logspace(lambdastart,lambdaend, numlambda);
    # Parameters: num_values: Number of lambda values to generate
    #             smaller_order_magnitude: smallest order of magnitude for generated lambdas
    #             bigger_order_magnitude: biggest order of magnitude for generated lambdas
    #             randomize: Boolean than determines if the order of lambdas is randomized in the final list.

    # Generate logarithmically spaced values
    log_values = np.linspace(smaller_order_magnitude, bigger_order_magnitude, num_values)
    values = 10**log_values

    if randomize:
        np.random.shuffle(values)
    return values

### -------------------- End of File --------------------